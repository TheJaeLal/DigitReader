{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Statements\n",
    "import numpy as np\n",
    "import mnist_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    #Construcutor\n",
    "    def __init__(self,neurons):\n",
    "        self.layers = len(neurons)\n",
    "        self.neurons = neurons\n",
    "        \n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        #Initialize weights\n",
    "        for i in range(1,self.layers):\n",
    "            #layer_weight = None\n",
    "            rows  = neurons[i]\n",
    "            cols = neurons[i-1]\n",
    "            #Creates a numpy array with dimensions rows x cols\n",
    "            #At the same time, initializes them with random normal distribution b/w 0 and 1\n",
    "            \n",
    "            #layer_weight = np.zeros((rows,cols))\n",
    "            layer_weight = np.random.randn(rows,cols)\n",
    "            self.weights.append(layer_weight)\n",
    "\n",
    "            #layer_bias = np.zeros((rows,1))\n",
    "            layer_bias = np.random.randn(rows,1)\n",
    "            self.biases.append(layer_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(network,X):\n",
    "    \n",
    "    #Stores the Aj values\n",
    "    Layer_Activations = []\n",
    "    \n",
    "    #Stores the Zj values\n",
    "    Weighted_Sums = []\n",
    "    \n",
    "    for i in range(1,network.layers):\n",
    "   \n",
    "        if i==1:\n",
    "            A = X\n",
    "        else:\n",
    "            A  = Layer_Activations[-1]\n",
    "        \n",
    "        W = network.weights[i-1]\n",
    "        B = network.biases[i-1]\n",
    "        Z = np.dot(W,A) + B\n",
    "        Weighted_Sums.append(Z)\n",
    "        A = sigmoid(Z)\n",
    "        Layer_Activations.append(A)\n",
    "\n",
    "    return (Weighted_Sums,Layer_Activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(network,test_data):\n",
    "\n",
    "    _,activations = feedforward(network,test_data[0])\n",
    "    \n",
    "    Output = activations[-1]\n",
    "    Target = test_data[1]\n",
    "    \n",
    "    #Output --> (10,Number_of_training_Samples)\n",
    "    #Target --> (Number_of_traing_Samples)\n",
    "    \n",
    "    Prediction = np.argmax(Output,axis=0)\n",
    "    #Prediction --> (Number_of_training_Samples,)    \n",
    "    \n",
    "    accuracy = (sum((Prediction == Target).astype(np.float32))/Target.shape[0])*100.0\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(z):\n",
    "    #print(\"sigmoid_derivative =\",sigmoid(z)*(1-sigmoid(z)) )\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_gradient(output,label):\n",
    "    #print(\"cost_gradient =\",output-label)\n",
    "    return output-label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(network,delta_output_layer,weighted_sums):\n",
    "    #Initialize error for all layers\n",
    "    #delta is the backpropogation error\n",
    "    \n",
    "    #Number of output layers --> first layer is an input layer, hence excluded\n",
    "    n_out = network.layers-1\n",
    "    \n",
    "    delta_all_layers = [None]*(n_out)\n",
    "    \n",
    "    delta_all_layers[-1] = delta_output_layer\n",
    "    \n",
    "    for i in range(n_out-2,-1,-1):\n",
    "        delta_all_layers[i] = np.dot(network.weights[i+1].transpose(),delta_all_layers[i+1])*sigmoid_derivative(weighted_sums[i])\n",
    "            \n",
    "    return delta_all_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(network,X,layer_activations,delta_all_layers,alpha):\n",
    "    \n",
    "    n_weights = network.layers-1\n",
    "    for i in range(n_weights):\n",
    "        \n",
    "#         print(\"shape of delta_all_layers[\",i,\"]:\",delta_all_layers[i].shape)\n",
    "#         print(\"shape of layer_activations[\",i,\"].transpose():\",delta_all_layers[i].transpose().shape)            \n",
    "        if i==0:\n",
    "            layer_input = X\n",
    "        else:\n",
    "            layer_input = layer_activations[i-1]\n",
    "        \n",
    "        dcdw = np.dot(delta_all_layers[i],layer_input.transpose())\n",
    "        dcb = np.average(delta_all_layers[i],axis=1).reshape(delta_all_layers[i].shape[0],1)\n",
    "#         print(\"shape of dcdw:\",dcdw.shape)\n",
    "#         print(\"shape of dcb:\",dcb.shape)\n",
    "#         print(\"shape of network.weights[\",i,\"]:\",network.weights[i].shape)\n",
    "        \n",
    "        network.weights[i] -= alpha * dcdw\n",
    "        network.biases[i] -= alpha * dcb\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GD(network,train_data,valid_data,alpha=1,epochs=50):\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        #Step 1: Calculate Output\n",
    "        weighted_sums,activations = feedforward(network,train_data[0])\n",
    "        \n",
    "        #Step 2: Calculate Error at final layer\n",
    "        delta_output_layer = cost_gradient(activations[-1],train_data[1])*sigmoid_derivative(weighted_sums[-1])\n",
    "        \n",
    "        #Step 3: Backpropogate Error\n",
    "        delta_all_layers = backprop(network,delta_output_layer,weighted_sums)\n",
    "        \n",
    "        #Step 4: Update Weights\n",
    "        update_weights(network,train_data[0],activations,delta_all_layers,1)\n",
    "\n",
    "        #Step 5: Validation Testing\n",
    "        accuracy = test(network,valid_data)\n",
    "\n",
    "        print(\"End of Epoch\",i,\" accuracy =\",accuracy)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,valid_data,test_data = mnist_loader.load_data_wrapper()\n",
    "network = Network([784,16,10])\n",
    "train_GD(network,train_data,valid_data,alpha=0.5,epochs=100)\n",
    "accuracy = test(network,test_data)\n",
    "print(\"On Testing Data: Accuracy =\",accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
