{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Statements\n",
    "import mnist_loader\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_sum(X,W,B):\n",
    "    #y = wtranspose.x + biases\n",
    "    #print(\"Dimensions of X,W,B:\",X.shape,W.shape,B.shape)\n",
    "    Y = X.dot(W) + B\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(X,network,Weighted_Sums,Inputs):\n",
    "    W = network.weights[0]\n",
    "    B = network.biases[0]\n",
    "    Inputs.append(X)\n",
    "    Y = weighted_sum(X,W,B)\n",
    "    Weighted_Sums.append(Y)\n",
    "    O = sigmoid(Y)\n",
    "    for i in range(1,len(network.weights)):\n",
    "        W = network.weights[i]\n",
    "        B = network.biases[i]\n",
    "        Inputs.append(O)\n",
    "        #Calculate weighted sum, wTx+B\n",
    "        Y = weighted_sum(O,W,B)\n",
    "        Weighted_Sums.append(Y)\n",
    "        O = sigmoid(Y)\n",
    "    #Final Output = maximum value from output classes (10 in the digit recognizer case)\n",
    "    #print(O)\n",
    "    #O = np.argmax(O,axis=1)+1\n",
    "    return O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backpropogate the error from output layer..\n",
    "def backprop(network,error_output_layer,Weighted_Sums):\n",
    "\n",
    "    #Create a list of length --> network.weights and initialize it with None\n",
    "    error = [None]*len(network.weights)\n",
    "    error[-1] = error_output_layer\n",
    "    \n",
    "    #Goes from 2nd last layer to 2nd layer\n",
    "    \n",
    "    #4layers\n",
    "    #error[3] --> output\n",
    "    #len(nw.wets) --> 3\n",
    "    #3-1 --> 2\n",
    "    #for i in range(2,0) --> i ka values --> [2,1]\n",
    "    #print(\"network.weights.len = \",len(network.weights))\n",
    "    \n",
    "    #print(\"some_str\",some_variable,some_other,var,\"end_str\")\n",
    "    #print(\"abc\"+str(some_var))\n",
    "    \n",
    "    #len -> 2, then i = 0\n",
    "    for i in range(len(network.weights)-2,-1,-1):\n",
    "        #print(\"***Backprop Error for layer :\",i)\n",
    "        \n",
    "        #Backprop error\n",
    "        #δl=((wl+1)Tδl+1)⊙σ′(zl),\n",
    "        \n",
    "        #1st iteration ---> i=2nd last, i+1=last/output\n",
    "        #print(\"Dimensions of weights[i+1],error[i+1]\",network.weights[i+1].shape,error[i+1].shape)\n",
    "    \n",
    "        #print(\"error[\",i+1,\"] =\",error[i+1])\n",
    "        #print(\"np.transpose(network.weights[\",i+1,\"]) =\",np.transpose(network.weights[i+1]))\n",
    "        #Dimensions of weights[i+1],error[i+1] (28, 10) (5, 10)\n",
    "        something = error[i+1].dot(np.transpose(network.weights[i+1])) \n",
    "        #something---> should be (5,28)\n",
    "        \n",
    "        \n",
    "        #print(\"Dimensions of something,weighted_sums[i]\",something.shape,Weighted_Sums[i].shape)\n",
    "        # Dimensions of something,weighted_sums[i] (28,) (5, 28)\n",
    "        \n",
    "        \n",
    "        #print(\"something = \",something)\n",
    "        #print(\"Weighted_Sums[\",i,\"] =\",Weighted_Sums[i])\n",
    "        error[i] = something * sigmoid_gradient(Weighted_Sums[i]) \n",
    "        #print(\"sigmoid_gradient(Weighted_Sums[\",i,\"]) =\",sigmoid_gradient(Weighted_Sums[i]))\n",
    "        \n",
    "        #error[0]--> (,)\n",
    "        # (x,y) hadamard (5,28) --> (5,28)\n",
    "        \n",
    "    #print(\"Error = \",error)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(network,Inputs,error,alpha):\n",
    "    \n",
    "    for i in range(len(network.weights)):\n",
    "\n",
    "        #Inputs contains an extra element X at the begining, hence i\n",
    "        #print(i,error[i]) #-->0,None, error[0]--None\n",
    "        \n",
    "        # dw = al-1 . errorl\n",
    "        dw = np.transpose(Inputs[i]).dot(error[i])\n",
    "\n",
    "        #Inputs[i] --> (5,784)\n",
    "        #error[i] --> (5,28)\n",
    "        # dw --> (784,28)\n",
    "        #Inputs --> list of all inputs. Inputs[0]--> X Inputs[1] --> O1\n",
    "        #Incoming Input --> to a Computational Neuron with some weights to that input\n",
    "\n",
    "        #error[i] --> for 5 training samples, you are getting change in biases\n",
    "        db = np.average(error[i],axis=0)\n",
    "        \"\"\"\n",
    "            [\n",
    "                [1,2,3,4,5],\n",
    "                [2,3,5,6,7]\n",
    "            \n",
    "            ]\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        network.weights[i] += alpha * dw\n",
    "        \n",
    "        #print(\"Dimensions of biases,db\",network.biases[i].shape,db.shape)\n",
    "        #Dimensions of biases,db (28,) (5, 28)\n",
    "        network.biases[i]  += alpha * db\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network,X,t,alpha=0.25,epochs=100):\n",
    "    Inputs = []\n",
    "    Weighted_Sums = []\n",
    "    for i in range(epochs):\n",
    "        #Calculate output, while storing the weighted_sums and input at each layer\n",
    "        O = forward_pass(X,network,Weighted_Sums,Inputs)\n",
    "        \n",
    "        #Calculate error in output layer\n",
    "        error_output_layer = calc_error(Weighted_Sums,O,t)\n",
    "        \n",
    "        display_error = np.average(O-t)\n",
    "        #print(display_error)\n",
    "        \n",
    "        print(\"Epoch\",i,\": Error = \"+str(display_error))\n",
    "        \n",
    "        #Update weights\n",
    "        error = backprop(network,error_output_layer,Weighted_Sums)\n",
    "        \n",
    "        update_weights(network,Inputs,error,alpha)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns the error in output layer...\n",
    "def calc_error(Weighted_Sums,O,t):\n",
    "    \n",
    "    #partial-derivative -->dL/d(o) --> do\n",
    "    \n",
    "    #do = -(t/O + (1-t)/(1-O))\n",
    "    \n",
    "    do = O - t\n",
    "    #t --> (5,)\n",
    "    #O --> (5,)\n",
    "    #do --> (5,)\n",
    "    \n",
    "    #sigma-dash(ZsubL) --> sig_grad\n",
    "    sig_grad = sigmoid_gradient(Weighted_Sums[-1])\n",
    "    #--->\n",
    "    #print(\"---Shape of last Weighted Sums layer = \",Weighted_Sums[-1].shape)\n",
    "    \n",
    "    #numpy array consisting of errors for each neuron in the output layer\n",
    "    #print(\"+++Shape of do,sig_grad\",do.shape,sig_grad.shape)\n",
    "    #[1,2,3,4,5] dot [[1,0,0,0,],[],...[]]\n",
    "    #print(\"sig_grad = \",sig_grad)\n",
    "    #print(\"do = \",do)\n",
    "    \n",
    "    error_in_output_layer = do * sig_grad\n",
    "    \n",
    "    #(5,10) hadamard (5,10) --> (5,10)\n",
    "    \n",
    "    #should return np array with dims (5,10)\n",
    "    #print(\"---Shape of Error in output_layer = \",error_in_output_layer.shape)\n",
    "    #print(\"Error_in_output_layer =\",error_in_output_layer)\n",
    "    return error_in_output_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activation Function\n",
    "def ReLU(z):\n",
    "    return np.maximum(z,0,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self,layers):\n",
    "        if len(layers)<2:\n",
    "            print(\"Cannot create Neural Network with less than 2 layers\")\n",
    "            return\n",
    "        self.layers = layers\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        for i in range(1, len(layers)):\n",
    "            rows = layers[i-1] #784\n",
    "            cols = layers[i] #28\n",
    "            layer_weight = np.random.random((rows,cols))\n",
    "            layer_bias = np.random.random(layers[i])\n",
    "            self.weights.append(layer_weight)\n",
    "            self.biases.append(layer_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net = Network([784,28,10])\n",
    "#my_net.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.random.random((5,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = np.array([\n",
    "#               [0,1,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0,0,0],\n",
    "#               [0,1,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0,0,0],\n",
    "#               [0,1,0,0,0,0,0,0,0,0]\n",
    "#             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "X = training_data[0]\n",
    "t = training_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Error = 0.899997758066\n",
      "Epoch 1 : Error = 0.899999624281\n",
      "Epoch 2 : Error = 0.899999684403\n",
      "Epoch 3 : Error = 0.899999724413\n",
      "Epoch 4 : Error = 0.899999753781\n",
      "Epoch 5 : Error = 0.899999776582\n",
      "Epoch 6 : Error = 0.899999794957\n",
      "Epoch 7 : Error = 0.899999810169\n",
      "Epoch 8 : Error = 0.899999823024\n",
      "Epoch 9 : Error = 0.899999834063\n",
      "Epoch 10 : Error = 0.89999984367\n",
      "Epoch 11 : Error = 0.899999852123\n",
      "Epoch 12 : Error = 0.899999859628\n",
      "Epoch 13 : Error = 0.899999866345\n",
      "Epoch 14 : Error = 0.899999872398\n",
      "Epoch 15 : Error = 0.899999877887\n",
      "Epoch 16 : Error = 0.899999882889\n",
      "Epoch 17 : Error = 0.899999887471\n",
      "Epoch 18 : Error = 0.899999891684\n",
      "Epoch 19 : Error = 0.899999895575\n",
      "Epoch 20 : Error = 0.899999899179\n",
      "Epoch 21 : Error = 0.899999902529\n",
      "Epoch 22 : Error = 0.899999905652\n",
      "Epoch 23 : Error = 0.899999908571\n",
      "Epoch 24 : Error = 0.899999911306\n",
      "Epoch 25 : Error = 0.899999913874\n",
      "Epoch 26 : Error = 0.899999916291\n",
      "Epoch 27 : Error = 0.899999918571\n",
      "Epoch 28 : Error = 0.899999920724\n",
      "Epoch 29 : Error = 0.899999922762\n",
      "Epoch 30 : Error = 0.899999924693\n",
      "Epoch 31 : Error = 0.899999926527\n",
      "Epoch 32 : Error = 0.89999992827\n",
      "Epoch 33 : Error = 0.89999992993\n",
      "Epoch 34 : Error = 0.899999931512\n",
      "Epoch 35 : Error = 0.899999933022\n",
      "Epoch 36 : Error = 0.899999934464\n",
      "Epoch 37 : Error = 0.899999935844\n",
      "Epoch 38 : Error = 0.899999937165\n",
      "Epoch 39 : Error = 0.899999938432\n",
      "Epoch 40 : Error = 0.899999939647\n",
      "Epoch 41 : Error = 0.899999940813\n",
      "Epoch 42 : Error = 0.899999941934\n",
      "Epoch 43 : Error = 0.899999943013\n",
      "Epoch 44 : Error = 0.899999944051\n",
      "Epoch 45 : Error = 0.899999945051\n",
      "Epoch 46 : Error = 0.899999946015\n",
      "Epoch 47 : Error = 0.899999946945\n",
      "Epoch 48 : Error = 0.899999947843\n",
      "Epoch 49 : Error = 0.89999994871\n",
      "Epoch 50 : Error = 0.899999949548\n",
      "Epoch 51 : Error = 0.899999950359\n",
      "Epoch 52 : Error = 0.899999951143\n",
      "Epoch 53 : Error = 0.899999951903\n",
      "Epoch 54 : Error = 0.899999952639\n",
      "Epoch 55 : Error = 0.899999953352\n",
      "Epoch 56 : Error = 0.899999954044\n",
      "Epoch 57 : Error = 0.899999954715\n",
      "Epoch 58 : Error = 0.899999955367\n",
      "Epoch 59 : Error = 0.899999956\n",
      "Epoch 60 : Error = 0.899999956614\n",
      "Epoch 61 : Error = 0.899999957212\n",
      "Epoch 62 : Error = 0.899999957793\n",
      "Epoch 63 : Error = 0.899999958358\n",
      "Epoch 64 : Error = 0.899999958908\n",
      "Epoch 65 : Error = 0.899999959443\n",
      "Epoch 66 : Error = 0.899999959965\n",
      "Epoch 67 : Error = 0.899999960473\n",
      "Epoch 68 : Error = 0.899999960968\n",
      "Epoch 69 : Error = 0.899999961451\n",
      "Epoch 70 : Error = 0.899999961922\n",
      "Epoch 71 : Error = 0.899999962381\n",
      "Epoch 72 : Error = 0.899999962829\n",
      "Epoch 73 : Error = 0.899999963266\n",
      "Epoch 74 : Error = 0.899999963694\n",
      "Epoch 75 : Error = 0.899999964111\n",
      "Epoch 76 : Error = 0.899999964518\n",
      "Epoch 77 : Error = 0.899999964917\n",
      "Epoch 78 : Error = 0.899999965306\n",
      "Epoch 79 : Error = 0.899999965687\n",
      "Epoch 80 : Error = 0.899999966059\n",
      "Epoch 81 : Error = 0.899999966424\n",
      "Epoch 82 : Error = 0.89999996678\n",
      "Epoch 83 : Error = 0.899999967129\n",
      "Epoch 84 : Error = 0.899999967471\n",
      "Epoch 85 : Error = 0.899999967805\n",
      "Epoch 86 : Error = 0.899999968133\n",
      "Epoch 87 : Error = 0.899999968454\n",
      "Epoch 88 : Error = 0.899999968768\n",
      "Epoch 89 : Error = 0.899999969076\n",
      "Epoch 90 : Error = 0.899999969378\n",
      "Epoch 91 : Error = 0.899999969674\n",
      "Epoch 92 : Error = 0.899999969965\n",
      "Epoch 93 : Error = 0.89999997025\n",
      "Epoch 94 : Error = 0.899999970529\n",
      "Epoch 95 : Error = 0.899999970804\n",
      "Epoch 96 : Error = 0.899999971073\n",
      "Epoch 97 : Error = 0.899999971337\n",
      "Epoch 98 : Error = 0.899999971596\n",
      "Epoch 99 : Error = 0.899999971851\n"
     ]
    }
   ],
   "source": [
    "train(my_net,X,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
